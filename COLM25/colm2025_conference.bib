@book{kafai1996constructionism,
      editor = {Kafai, Yasmin B. and Resnick, Mitchel},
      title = {Constructionism in Practice: Designing, Thinking, and Learning in a Digital World},
      publisher = {Routledge},
      year = {1996}
}

@inproceedings{kazemitabaar2024codeaid,
  author = {Kazemitabaar, Majeed and Ye, Runlong and Wang, Xiaoning and Henley, Austin Zachary and Denny, Paul and Craig, Michelle and Grossman, Tovi},
  title = {Code{A}id: Evaluating a classroom deployment of an LLM-based programming assistant that balances student and educator needs},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
  year = {2024}
}

@inproceedings{10.5555/3666122.3668141,
author = {Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and Gupta, Shashank and Majumder, Bodhisattwa Prasad and Hermann, Katherine and Welleck, Sean and Yazdanbakhsh, Amir and Clark, Peter},
title = {{SELF-REFINE: iterative refinement with self-feedback}},
year = {2023},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Like humans, large language models (llms) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from llms through iterative feedback and refinement. The main idea is to generate an initial output using an llm; then, the same llm provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single llm as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (gpt-3.5 and GPT-4) llms. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same llm using conventional one-step generation, improving by ~20\% absolute on average in task performance. Our work demonstrates that even state-of-the-art llmS like GPT-4 can be further improved at test-time using our simple, standalone approach. Code and data at https://selfrefine.info/.},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {2019},
numpages = {61},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

@book{AERA2014Standards,
  title={Standards for Educational and Psychological Testing},
  author={American Educational Research Association and American Psychological Association and National Council on Measurement in Education and Joint Committee on Standards for Educational and Psychological Testing (U.S.)},
  isbn={9780935302356},
  lccn={2012376121},
  year={2014},
  publisher={American Educational Research Association}
}

@inproceedings{Brennan2012CTFrameworks,
  author = {Brennan, Karen and Resnick, Mitchel},
  title = {New frameworks for studying and assessing the development of computational thinking},
  booktitle = {Proceedings of the 2012 Annual Meeting of the American Educational Research Association},
  year = {2012}
}

@article{Koedinger2013ITS,
  title={New potentials for data-driven intelligent tutoring system development and optimization},
  author={Koedinger, Kenneth R and Brunskill, Emma and Baker, Ryan SJd and McLaughlin, Elizabeth A and Stamper, John},
  journal={AI Magazine},
  volume={34},
  number={3},
  pages={27--41},
  year={2013}
}

@article{Kumar2025CounterfactualLLMs,
  author = {Kumar, Santhosh Anand Subramanian and Yan, Haozhe and Perepa, Srija and Yue, Meng and Yao, Zhiyuan},
  title = {{Can LLMs Simulate Personas with Reversed Performance? A Benchmark for Counterfactual Instruction Following}},
  journal = {arXiv preprint arXiv:2504.06460},
  year = {2025}
}

@article{Lye2014CTReview,
  author = {Lye, Sze Yee and Koh, Joyce Hwee Ling},
  title = {Review on teaching and learning of computational thinking through programming},
  journal = {Computers in Human Behavior},
  volume = {41},
  number = {C},
  pages = {51--61},
  year = {2014}
}

@inproceedings{Mannekote2024LLMLearnerSim,
  author = {Mannekote, Abhay and Davies, Amanda and Kang, Jay and Boyer, Kristy Elizabeth},
  title = {Can {LLM}s Reliably Simulate Human Learner Actions? {A} Simulation Authoring Framework for Open-Ended Learning Environments},
year = {2025},
publisher = {AAAI Press},
abstract = {Simulating learner actions helps stress-test open-ended interactive learning environments and prototype new adaptations before deployment. While recent studies show the promise of using large language models (LLMs) for simulating human behavior, such approaches have not gone beyond rudimentary proof-of-concept stages due to key limitations. First, LLMs are highly sensitive to minor prompt variations, raising doubts about their ability to generalize to new scenarios without extensive prompt engineering. Moreover, apparently successful outcomes can often be unreliable, either because domain experts unintentionally guide LLMs to produce expected results, leading to self-fulfilling prophecies; or because the LLM has encountered highly similar scenarios in its training data, meaning that models may not be simulating behavior so much as regurgitating memorized content. To address these challenges, we propose HYP-MIX, a simulation authoring framework that allows experts to develop and evaluate simulations by combining testable hypotheses about learner behavior. Testing this framework in a physics learning environment, we found that GPT-4 Turbo maintains calibrated behavior even as the underlying learner model changes, providing the first evidence that LLMs can be used to simulate realistic behaviors in open-ended interactive learning environments, a necessary prerequisite for useful LLM behavioral simulation.},
booktitle = {Proceedings of the Thirty-Ninth AAAI Conference on Artificial Intelligence and Thirty-Seventh Conference on Innovative Applications of Artificial Intelligence and Fifteenth Symposium on Educational Advances in Artificial Intelligence},
articleno = {3277},
numpages = {9},
series = {AAAI'25/IAAI'25/EAAI'25}
}

@book{Papert1991Constructionism,
  title={Constructionism.},
  author={Harel, Idit Ed and Papert, Seymour Ed},
  year={1991},
  publisher={Ablex Publishing}
}

@book{Patt2003ComputingSystems,
  author = {Patt, Yale N. and Patel, Sanjay J.},
  title = {Introduction to Computing Systems: From Bits and Gates to C and Beyond},
  publisher = {McGraw-Hill Higher Education},
  year = {2003}
}

@incollection{sweller2011cognitive,
  title={Cognitive load theory},
  author={Sweller, John},
  booktitle={Psychology of learning and motivation},
  volume={55},
  pages={37--76},
  year={2011},
  publisher={Elsevier}
}

@article{roscoe2007understanding,
  title={{Understanding Tutor Learning: Knowledge-Building and Knowledge-Telling in Peer Tutors' Explanations and Questions}},
  author={Roscoe, Rod D and Chi, Michelene T. H.},
  journal={Review of Educational Research},
  volume={77},
  number={4},
  pages={534--572},
  year={2007},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{chase2009teachable,
  title={{Teachable Agents and the Prot{\'e}g{\'e} Effect: Increasing the Effort Towards Learning}},
  author={Chase, Catherine C and Chin, Doris B and Oppezzo, Marily A and Schwartz, Daniel L},
  journal={Journal of Science Education and Technology},
  volume={18},
issue={4},
  pages={334--352},
  year={2009},
  publisher={Springer Nature}
}

@inproceedings{raihan2025llms,
  author = {Raihan, Nishat and Siddiq, Mohammed Latif and Santos, Joanna C.S. and Zampieri, Marcos},
  title = {Large Language Models in Computer Science Education: A Systematic Literature Review},
  booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
  pages = {938--944},
  year = {2025},
  doi = {10.1145/3641554.3701863},
  publisher = {ACM}
}


@article{bastani2024generative,
  title={Generative {AI} Can Harm Learning},
  author={Bastani, Hamsa and Bastani, Osbert and Sungu, Alp and Ge, Haosen and Kabakcı, {\"O}zge and Mariman, Rei},
  journal={The Wharton School Research Paper},
  year={2024},
  month={July},
  url={https://ssrn.com/abstract=4895486},
  doi={10.2139/ssrn.4895486}
}

@article{choi2023llms,
  author = {Choi, Jun Ho and Garrod, Oliver and Atherton, Paul and Joyce-Gibbons, Andrew and Mason-Sesay, Miriam and Björkegren, Daniel},
  title = {{Are LLMs Useful in the Poorest Schools? TheTeacher.AI in Sierra Leone}},
  year = {2023},
  journal ={arXiv preprint arXiv:2310.02982}
}

@article{lee2022generative,
title={Generative AI in the Classroom: Can Students Remain Active Learners?}, 
      author={Rania Abdelghani and Hélène Sauzéon and Pierre-Yves Oudeyer},
      year={2023},
      journal={arXiv preprint arXiv:2310.03192}
}

@misc{voila,
author = {{The Voila Development Team}},
title = {Voil\'a},
howpublished = {\url{https://voila.readthedocs.io/en/stable/}},
year = {2024}
}

Here is a BibTeX entry for the "And Voici!" blog post:
@article{yang2024harnessing,
  title={Harnessing the power of {LLMs} in practice: A survey on {ChatGPT} and beyond},
  author = {Yang, Jingfeng and Jin, Hongye and Tang, Ruixiang and Han, Xiaotian and Feng, Qizhang and Jiang, Haoming and Zhong, Shaochen and Yin, Bing and Hu, Xia},
  journal={ACM Transactions on Knowledge Discovery from Data},
  volume={18},
  number={6},
  pages={1--32},
  year={2024},
  publisher={ACM New York, NY}
}

@inproceedings{cloutier2023fine,
  title={Fine-tuned generative {LLM} oversampling can improve performance over traditional techniques on multiclass imbalanced text classification},
  author={Cloutier, Nicolas Antonio and Japkowicz, Nathalie},
  booktitle={2023 IEEE International Conference on Big Data (BigData)},
  pages={5181--5186},
  year={2023},
  organization={IEEE}
}

@inproceedings{denny2024desirable,
  author = {Denny, Paul and MacNeil, Sam and Savelka, Jaromir and Porter, Leo and Luxton-Reilly, Andrew},
  title = {Desirable Characteristics for AI Teaching Assistants in Programming Education},
  booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
  year = {2024},
  pages = {408--414},
  address = {Turku, Finland}
}

@article{wang2024large,
  title={Large language models for education: A survey and outlook},
  author={Wang, Shen and Xu, Tianlong and Li, Hang and Zhang, Chaoli and Liang, Joleen and Tang, Jiliang and Yu, Philip S and Wen, Qingsong},
  journal={arXiv preprint arXiv:2403.18105},
  year={2024}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@inproceedings{liu2024beyond,
  title={Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science},
  author={Liu, Mengqi and M'Hiri, Faten},
  booktitle={Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
  pages={743--749},
  year={2024}
}

@article{min2023beyond,
  title={Beyond accuracy: Evaluating self-consistency of code large language models with identity chain},
  author={Min, Marcus J and Ding, Yangruibo and Buratti, Luca and Pujar, Saurabh and Kaiser, Gail and Jana, Suman and Ray, Baishakhi},
  journal={arXiv preprint arXiv:2310.14053},
  year={2023}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{anil2023palm,
  title={{PaLM} 2 technical report},
  author={Anil, Rohan and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}

@article{anthropic2024claude,
  title={The Claude 3 model family: {Opus, Sonnet, Haiku}},
  author={Anthropic, AI},
  journal={Claude-3 Model Card},
  year={2024},
  url = {https://assets.anthropic.com/m/61e7d27f8c8f5919/original/Claude-3-Model-Card.pdf}
}

@article{achiam2023gpt,
  title={{GPT}-4 technical report},
  author={{OpenAI} and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{kalyan2023survey,
  title={A survey of {GPT}-3 family large language models including {ChatGPT} and {GPT}-4},
  author={Kalyan, Katikapalli Subramanyam},
  journal={Natural Language Processing Journal},
  pages={100048},
  year={2023},
  publisher={Elsevier}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{reid2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={{Gemini Team Google} and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@article{touvron2023llama,
  title={{LLaMa}: Open and efficient foundation language models},
  author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@inproceedings{chu2023survey,
   title = "Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future",
    author = "Chu, Zheng  and
      Chen, Jingchang  and
      Chen, Qianglong  and
      Yu, Weijiang  and
      He, Tao  and
      Wang, Haotian  and
      Peng, Weihua  and
      Liu, Ming  and
      Qin, Bing  and
      Liu, Ting",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    pages = "1173--1203",
}

@inproceedings{zhou2022least,
  title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and Ed Chi},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@inproceedings{bartsch-etal-2023-self,
    title = "Self-Consistency of Large Language Models under Ambiguity",
    author = "Bartsch, Henning  and
      Jorgensen, Ole  and
      Rosati, Domenic  and
      Hoelscher-Obermaier, Jason  and
      Pfau, Jacob",
    booktitle = "Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP",
    month = dec,
    year = "2023",
    address = "Singapore",
    doi = "10.18653/v1/2023.blackboxnlp-1.7",
    pages = "89--105",
}

@article{chen2023universal,
  title={Universal self-consistency for large language model generation},
  author={Chen, Xinyun and Aksitov, Renat and Alon, Uri and Ren, Jie and Xiao, Kefan and Yin, Pengcheng and Prakash, Sushant and Sutton, Charles and Wang, Xuezhi and Zhou, Denny},
  journal={arXiv preprint arXiv:2311.17311},
  year={2023}
}

@article{touvron2023llama2,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
journal = {arXiv preprint arXiv:2307.09288}
}

@misc{meta2024llama3,
  title={Introducing Meta {LLaMA} 3: The most capable openly available {LLM} to date},
  author={{Meta AI}},
  year={2024},
  url={https://ai.meta.com/blog/meta-llama-3/}
}

@article{jeon_large_2023,
	title = {Large language models in education: A focus on the complementary relationship between human teachers and {ChatGPT}},
	volume = {28},
	shorttitle = {Large language models in education},
	pages = {15873--15892},
	number = {12},
        year = {2023},
	journal = {Education and Information Technologies},
	shortjournal = {Educ Inf Technol},
	author = {Jeon, Jaeho and Lee, Seongyong},
	urldate = {2024-04-27},
	date = {2023-12-01},
	langid = {english},
	keywords = {{ChatGPT}, {AIEd}, Artificial intelligence, Chatbot, Human–computer interaction, Large language model, Large language model-powered chatbot},
}

@article{british_university_vietnam_academic_2023,
	title = {Academic integrity considerations of {AI} Large Language Models in the post-pandemic era: {ChatGPT} and beyond},
	volume = {20},
issue = {2},
journal = {Journal of University Teaching \& Learning Practice},
	doi = {10.53761/1.20.02.07},
	shorttitle = {Academic integrity considerations of {AI} Large Language Models in the post-pandemic era},
	abstract = {This paper explores the academic integrity considerations of students’ use of Artificial Intelligence ({AI}) tools using Large Language Models ({LLMs}) such as {ChatGPT} in formal assessments. We examine the evolution of these tools, and highlight the potential ways that {LLMs} can support in the education of students in digital writing and beyond, including the teaching of writing and composition, the possibilities of co-creation between humans and {AI}, supporting {EFL} learners, and improving Automated Writing Evaluations ({AWE}). We describe and demonstrate the potential that these tools have in creating original, coherent text that can avoid detection by existing technological methods of detection and trained academic staff alike, demonstrating a major academic integrity concern related to the use of these tools by students. Analysing the various issues related to academic integrity that {LLMs} raise for both Higher Education Institutions ({HEIs}) and students, we conclude that it is not the student use of any {AI} tools that defines whether plagiarism or a breach of academic integrity has occurred, but whether any use is made clear by the student. Deciding whether any particular use of {LLMs} by students can be defined as academic misconduct is determined by the academic integrity policies of any given {HEI}, which must be updated to consider how these tools will be used in future educational environments.},
	number = {2},
	journaltitle = {Journal of University Teaching and Learning Practice},
	shortjournal = {{JUTLP}},
	author = {Perkins, Mike},
	urldate = {2024-04-27},
	date = {2023-02-22},
year = {2023},
	langid = {english},
	file = {British University, Vietnam and Perkins - 2023 - Academic integrity considerations of AI Large Lang.pdf:/Users/junli/Zotero/storage/IQMMV6GZ/British University, Vietnam and Perkins - 2023 - Academic integrity considerations of AI Large Lang.pdf:application/pdf},
}

@inproceedings{liu_teaching_2024,
	location = {New York, {NY}, {USA}},
	title = {Teaching {CS}50 with {AI}: Leveraging Generative Artificial Intelligence in Computer Science Education},
	series = {{SIGCSE} 2024},
	shorttitle = {Teaching {CS}50 with {AI}},
	abstract = {In Summer 2023, we developed and integrated a suite of {AI}-based software tools into {CS}50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial {AI} software such as {ChatGPT}, {GitHub} Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had "a personal tutor.'' Our findings suggest that integrating {AI} thoughtfully into educational settings enhances the learning experience by providing continuous, customized support and enabling human educators to address more complex pedagogical issues. In this paper, we detail how {AI} tools have augmented teaching and learning in {CS}50, specifically in explaining code snippets, improving code style, and accurately responding to curricular and administrative queries on the course's discussion forum. Additionally, we present our methodological approach, implementation details, and guidance for those considering using these tools or {AI} generally in education.},
	pages = {750--756},
	booktitle = {Proceedings of the 55th {ACM} Technical Symposium on Computer Science Education V. 1},
	author = {Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.},  
        year = {2024},
	urldate = {2024-04-30},
	date = {2024-03-07},
	keywords = {ai, artificial intelligence, generative ai, large language models, llms},
	file = {Full Text PDF:/Users/junli/Zotero/storage/8N7PYC4F/Liu et al. - 2024 - Teaching CS50 with AI Leveraging Generative Artif.pdf:application/pdf},
}

@inproceedings{markel_gpteach_2023,
	location = {New York, {NY}, {USA}},
	title = {{GPTeach}: Interactive {TA} Training with {GPT}-based Students},
	series = {L@S '23},
	shorttitle = {{GPTeach}},
	abstract = {Interactive and realistic teacher training is hard to scale. This is a key issue for learning at scale, as inadequate preparation can negatively impact both students and teachers. What if we could make the teacher training experience more engaging and, as a downstream effect, reduce the potential for harm that teachers-in-training could inflict on students? We present {GPTeach}, an interactive chat-based teacher training tool that allows novice teachers to practice with simulated students. We performed two studies to evaluate {GPTeach}: one think-aloud study and one A/B test between our tool and a baseline. Participants took the role of a teaching assistant conducting office hours with two {GPT}-simulated students. We found that our tool provides the opportunity for teachers to get valuable teaching practice without the pressures of affecting real students, allowing them to iterate their responses both during and across sessions. Additionally, participants enjoyed flexibility in tailoring their responses according to the varied personas, needs, and learning goals. In this paper, we provide quantitative results and qualitative observations to inform future work in this area. We conclude with a discussion of actionable design ideas for such systems, as well as other ways to use this tool for evaluating teachers and students. {GPTeach} has recently been deployed into the teacher training component of an online course with over 800 novice teachers.},
	pages = {226--236},
	booktitle = {Proceedings of the Tenth {ACM} Conference on Learning @ Scale},
	publisher = {Association for Computing Machinery},
	author = {Markel, Julia M. and Opferman, Steven G. and Landay, James A. and Piech, Chris},
        year = {2023},
	urldate = {2024-05-01},
	date = {2023-07-20},
	keywords = {{GPT}-simulated students, scalable teacher training},
	file = {Full Text PDF:/Users/junli/Zotero/storage/Z8XDG5SG/Markel et al. - 2023 - GPTeach Interactive TA Training with GPT-based St.pdf:application/pdf},
}

@inproceedings{Brown2020LanguageMA,
author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
title = {Language models are few-shot learners},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {159},
numpages = {25},
location = {Vancouver, BC, Canada},
series = {NIPS '20}
}

